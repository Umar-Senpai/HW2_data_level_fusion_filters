# Data Level Fusion Filters using Point Cloud Library with QT5/VTK GUI
This repository contains the solution to homework 2 for 3D Sensing and Sensor Fusion course

## Subtask 1: Algorithms
The main C++ file in `/src` named `main.cpp` implements the different algorithms for filtering and upsampling images. The implemented algorithms are:

* Bilateral Filter
* Bilateral Median Filter
* Guided Filters
  * Joint Bilateral and Joint Bilateral Median Filter
* Upsampling Algorithms
  * Joint Bilateral Upsampling and Joint Bilateral Median Upsampling
  * Iterative Upsampling

The main file will first run the Gaussian and Bilateral (+Median) Filters on lena.png in data folder and the other filters on the given argument path. The algorithms can be run on a color-disparity image using the following command
```
./Main_Filters PATH_TO_IMAGE_PAIR OUTPUT
```
The C++ file will apply the guided filters and upsampling algorithms on the provided images and generate output in OpenCV windows. The code will also output different errors (SSD, RMSE, PSNR, SSIM, NCC etc.) on the terminal for each filter. After the OpenCV windows are open the code will stop and wait for key press to move forward

### Generating results for evaluation
We need to generate upsampled disparities for 12 pairs of color-disparity images. After demonstrating that our filters are working, press any key to close the openCV windows. The code will now apply the JBU, JBMU and IU algorithm on 12 sets of color-disparity images in our `data` folder. The outputs will then be stored inside `results` folder

An example format of these files is shown:
```
Art_window_3_JBU.png
Art_window_3_JBMU.png
Art_window_3_IU.png
Art_window_3_processing_time.txt
Art_window_3_errors.txt
```
The first three are disparity images in `PNG` format. The last two are text files containing the processing time of each algorithm in seconds and the three errors (RMSE, PSNR, SSIM) of each algorithm. These files will be generated for each of the 12 image-disparity pairs.

Different parameters such as window_size, sigma etc. can be changed for fine tuning in the main function. We also need to evaluate optimal sigmas for evaluation purposes. For this, the spatial sigma is dependent on window_size and we found that `window_size=1` works best which is equal to `spatial_sigma=0.4`. 

For spectral sigma, we have written another `for` loop to calculate error values on different spectral sigma values. An array of 10 spectral sigma values is defined and we will run Iterative Upsampling algorithm on each sigma with a fixed window_size of 7. The generated results are saved inside `results/sigma` directory. It's imperative to have a `sigma` directory inside `results`.

## Subtask 2: 3D Display
Another C++ file in `/src` named `disparity2pc.cpp` implements functions to generate a point cloud from the disparity images and to visualize these point clouds. Using the Point Cloud Library in C++, it performs normals computation on point cloud and triangulation of the point cloud. We need the Point Cloud Library to run this file. A simple tutorial to install PCL library is given here: https://pcl.readthedocs.io/projects/tutorials/en/master/compiling_pcl_posix.html

After the library is compiled and installed, we can run the file on an image using the following command
```
./Disparity_2_point_cloud Disparity_Image output
```
By taking the disparity image, it first converts the image to point cloud and then visualizes the simple point cloud along with its normals and triangulation. In the end, it will generate three files. An example format of these files is shown:
```
output.xyz
output.pcd
output_mesh.obj
```
The `output.xyz` and `output.pcd` files are the same, and contains `XYZ` coordinates of point cloud. The `output_mesh.obj` file contains the polygon mesh generated by triangulation. It can be viewed in `MeshLab` or other software. `PCL` also provides visualization tools and running the above code will automatically display point cloud, normal and triangulation in a separate windows. You can press R to center the axiss and click and move cursor to change view of the point cloud. Different parameters such as search radius for normal and triangulation can be changed and fine tuned. 

### GUI Application
The C++ file in `/src` named `main_gui.cpp` and `pclviewer.cpp` implements the GUI application to tune window size and spectral sigma. We can also view the error values and change the point cloud size. 

We are using VTK and QT packages to implement the GUI and display the resulting point clouds. The skeleton code is taken from: https://pcl.readthedocs.io/projects/tutorials/en/latest/qt_visualizer.html

We have modified the code for our application. We can tune window size and spectral sigma with a slider. After the slider is released, the Iterative Upsampling algorithm will run on the new parameters and display the resulting point cloud in the right view window. A sample output and GUI application is shown below:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207601173-1b49bc66-74e5-4432-856a-0d7c5c9d6f92.png" width="500" height="300" />
</p>

## Subtask 3: Evaluation
In addition to the above visualizations by PCL library, we will be using python and matplotlib to display our results. These results include displaying metric (RMSE, PSNR, SSIM) values on different pairs of images using the three algorithms (JBU, JBMU, IU). We are also plotting processing times of the three algorithms. In order to find optimal sigma and window size for Iterative Upsampling algorithm, we are plotting RMSE/SSIM vs sigma values. In the end, some difference images are shown by comparing a few samples with their respective ground truths. The python script can be run using the following command
```
python3 evaluation.py
```
The `evaluation.py` script also uses `python_utils.py` which are just utility functions separated out for readability. The results are discussed below:

## Evaluation Results
### Demonstration
In order to demonstrate that all of our filters work, the resulting outputs of each filter are shown below.

The lena image with added noise is:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207584218-cc7312d1-7cb8-40ed-877d-60ba4eb85630.png" width="400" height="400" />
</p>

Gaussian Filter           |  Bilateral Filter | Bilateral Median Filter
:-------------------------:|:-------------------------:|:-------------------------:
![Gaussian](https://user-images.githubusercontent.com/31202659/207582228-d7c045dc-132e-4158-a8d3-729a150cf3ce.png) |  ![OurBilateralFiler](https://user-images.githubusercontent.com/31202659/207582274-94073b78-e883-4759-b2e0-4a1914a1130b.png) | ![OurBilateralMedianFiler](https://user-images.githubusercontent.com/31202659/207582310-14f2d695-38a5-48d3-aad3-cd3efa55f8a1.png)

On the terminal, the errors are printed for each implemented filter. An example for the above three filters is shown:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207582834-17876244-ffbf-41b6-9c07-3adedd1acb61.png" width="400" height="400" />
</p>

For the other filters, we are using a downsampled disparity map downloaded from ThirdSize Middlebury dataset and using the original image to upsample it. 
Original Image           |  Downsampled Disparity | Ground Truth Disparity
:-------------------------:|:-------------------------:|:-------------------------:
![view1](https://user-images.githubusercontent.com/31202659/207583132-a68a84e1-b0dc-4213-9b71-369fb9e917c4.png) |  ![lowres_disp1](https://user-images.githubusercontent.com/31202659/207583203-8a38effd-3d75-4a5e-a57f-a7650fcd85d7.png) | ![disp1](https://user-images.githubusercontent.com/31202659/207583170-5bce36ab-e892-4c62-b2b7-efefb25ac621.png)

The results of Guided filters are:
Ground Truth Disparity           |  Joint Bilateral | Joint Bilateral Median
:-------------------------:|:-------------------------:|:-------------------------:
![disp1](https://user-images.githubusercontent.com/31202659/207583170-5bce36ab-e892-4c62-b2b7-efefb25ac621.png) | ![OurJointBilateralFiler](https://user-images.githubusercontent.com/31202659/207583618-94ce1bd9-aeb9-4881-a316-8b20050c61cd.png) | ![OurJointBilateralMedianFiler](https://user-images.githubusercontent.com/31202659/207583650-1387ba0b-c269-45ee-bd1b-107f90b97de3.png)

The results of Upsampling algorithms are:
JBU          |  JBMU | Iterative Upsampling
:-------------------------:|:-------------------------:|:-------------------------:
![OurJointBilateralUpsamplingFiler](https://user-images.githubusercontent.com/31202659/207583967-2d01d432-9af9-4d39-a0dd-ca6eac6da395.png) | ![OurJointBilateralMedianUpsamplingFiler](https://user-images.githubusercontent.com/31202659/207583986-20839a26-0ec9-483f-94ea-734d7e6ba1b9.png) | ![Iterative_Upsampling](https://user-images.githubusercontent.com/31202659/207584010-6fe9e131-05ec-499e-a803-605f5e1c6c7e.png)

### Comparison results
We have run the algorithm on 12 color-disparity pairs from Middlebury 2005 and 2006 dataset.The upsampling algorithms are run for 3 different window sizes and 3 different metrics (RMSE, PSNR, SSIM) and 3 different algorithms (JBU, JBMU, IU). The results for each metric are shown in a separate plot.

#### Difference Image
To better visualize these results, we have generated a difference image between the IU/JBMU algorithm and ground truth for the Art Image pair. The results are displayed below:

###### Iterative Algorithm Window Size 3
![Screenshot from 2022-12-14 13-46-31](https://user-images.githubusercontent.com/31202659/207587409-2b28acab-3155-4275-b6f7-df0437d96070.png)

###### Iterative Algorithm Window Size 5
![Screenshot from 2022-12-14 13-46-43](https://user-images.githubusercontent.com/31202659/207587450-dc0558ae-2e73-4ffa-92f9-bb36d5ada33c.png)

###### JBMU Window Size 3
![Screenshot from 2022-12-14 13-46-53](https://user-images.githubusercontent.com/31202659/207587498-f8f74e4b-68ab-4232-89b7-f90952824206.png)

#### RMSE
The plot below shows results for RMSE. Each subplot belongs to one image pair and in each subplot, we have a bar representing each algorithm. 

![Figure_1](https://user-images.githubusercontent.com/31202659/207587897-0281e17f-edf4-45ca-9c54-03191d10bda9.png)

We can see that with increasing window_size, the RMSE increases for almost all cases. Meaning that the error is getting big with the window_size.

#### SSIM
The SSIM or Structural Similarity Index Measure gives a value of 1 for perfect match. Below we can observer SSIM for each image pair.

![Figure_3](https://user-images.githubusercontent.com/31202659/207598226-c930495c-f8b7-4aff-9d0d-d3948302dd93.png)

The SSIM values are very high and changing window size doesn't affect that much.

#### PSNR
The PSNR or Peak-Signal-to-Noise-Ratio results are shown below:

![Figure_2](https://user-images.githubusercontent.com/31202659/207592995-6b7c509a-aff7-4316-a424-e28f2ac219bd.png)

The trend followed by PSNR is almost the same as SSIM and the change is small between window sizes. 

#### Processing Time
Next, we take a look at the processing time of different algorithms with different window sizes. The processing time can be affected by multiple things but the median appraoch takes the most time as evident from the figure below

![Figure_4](https://user-images.githubusercontent.com/31202659/207598735-62ee0287-bba5-4968-ad33-9b88c71c3eac.png)

But the general trend is the same that with increasing window_size, we see a good amount of jump in processing time.

#### Optimal Sigma
To calculate spatial sigma, we are using window_size and the window_size of 1 produces the best results. In order to figure out the optimal spectral sigma, we will run the code for different sigma values on a window size of 7 and the following plots are obtained

<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207599375-340fb2e5-8eaf-43a3-b837-07390a699bdb.png" width="500" height="300" />
</p>

Also for SSIM values:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207599726-1dd22596-1bfc-492c-9616-367918799e25.png" width="500" height="300" />
</p>

#### 3D Displays

We have generated some screenshots of 3D displays with Upsampled disparity from Iterative Upsampling algorithm:

Downsampled DP Point cloud             |  Normal Estimation | Triangulated surface
:-------------------------:|:-------------------------:|:-------------------------:
![Screenshot from 2022-12-14 14-53-13](https://user-images.githubusercontent.com/31202659/207600456-d85649a5-239f-4ad5-8a22-4e82d60407c2.png)  |  ![Screenshot from 2022-12-14 14-53-23](https://user-images.githubusercontent.com/31202659/207600481-2ccdc9af-15ac-460e-9d7b-beb92b09ab81.png) | ![Screenshot from 2022-12-14 14-54-00](https://user-images.githubusercontent.com/31202659/207600504-6001b57f-b84c-4b23-bd16-852b771c033b.png)

We can tune the sigma and window size using the GUI interface:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207601173-1b49bc66-74e5-4432-856a-0d7c5c9d6f92.png" width="500" height="300" />
</p>

We can tune different parameters and observe the point cloud and RMSE/PSNR values to see where the optimal values lie:
<p align="center">
  <img src="https://user-images.githubusercontent.com/31202659/207601189-06db0972-c07b-442c-a91f-e75303366308.png" width="500" height="300" />
</p>

### Results Folder
In the repository, the results folder contain all the generated disparity images for metric evaluations. It also contains some other results. The name of the files display the algorithm and window size/sigma value used for each output. 
